{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 10 samples per chain. Reliable r-hat and ESS diagnostics require longer chains for accurate estimate.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m     Y_obs \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_obs\u001b[39m\u001b[38;5;124m'\u001b[39m, mu\u001b[38;5;241m=\u001b[39mblack_box_likelihood(X_a), sigma\u001b[38;5;241m=\u001b[39msigma, observed\u001b[38;5;241m=\u001b[39mY_observed)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Perform MCMC sampling\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     trace \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m10\u001b[39m, tune\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Plot posterior distributions of the aleatory variables\u001b[39;00m\n\u001b[0;32m     50\u001b[0m pm\u001b[38;5;241m.\u001b[39mplot_posterior(trace, var_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_a1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_a2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_a3\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:714\u001b[0m, in \u001b[0;36msample\u001b[1;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[0;32m    711\u001b[0m         auto_nuts_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    713\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m step \u001b[38;5;241m=\u001b[39m assign_step_methods(model, step, methods\u001b[38;5;241m=\u001b[39mpm\u001b[38;5;241m.\u001b[39mSTEP_METHODS, step_kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nuts_sampler \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpymc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, NUTS):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:237\u001b[0m, in \u001b[0;36massign_step_methods\u001b[1;34m(model, step, methods, step_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m         selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    230\u001b[0m             methods_list,\n\u001b[0;32m    231\u001b[0m             key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m method, var\u001b[38;5;241m=\u001b[39mrv_var, has_gradient\u001b[38;5;241m=\u001b[39mhas_gradient: method\u001b[38;5;241m.\u001b[39m_competence(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    232\u001b[0m                 var, has_gradient\n\u001b[0;32m    233\u001b[0m             ),\n\u001b[0;32m    234\u001b[0m         )\n\u001b[0;32m    235\u001b[0m         selected_steps\u001b[38;5;241m.\u001b[39msetdefault(selected, [])\u001b[38;5;241m.\u001b[39mappend(var)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m instantiate_steppers(model, steps, selected_steps, step_kwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:138\u001b[0m, in \u001b[0;36minstantiate_steppers\u001b[1;34m(model, steps, selected_steps, step_kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m         args \u001b[38;5;241m=\u001b[39m step_kwargs\u001b[38;5;241m.\u001b[39mget(name, {})\n\u001b[0;32m    137\u001b[0m         used_keys\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[1;32m--> 138\u001b[0m         step \u001b[38;5;241m=\u001b[39m step_class(\u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mvars\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    139\u001b[0m         steps\u001b[38;5;241m.\u001b[39mappend(step)\n\u001b[0;32m    141\u001b[0m unused_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(step_kwargs)\u001b[38;5;241m.\u001b[39mdifference(used_keys)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\step_methods\\hmc\\nuts.py:180\u001b[0m, in \u001b[0;36mNUTS.__init__\u001b[1;34m(self, vars, max_treedepth, early_max_treedepth, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_treedepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, early_max_treedepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Set up the No-U-Turn sampler.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    `pm.sample` to the desired number of tuning steps.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mvars\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_treedepth \u001b[38;5;241m=\u001b[39m max_treedepth\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_max_treedepth \u001b[38;5;241m=\u001b[39m early_max_treedepth\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\step_methods\\hmc\\base_hmc.py:109\u001b[0m, in \u001b[0;36mBaseHMC.__init__\u001b[1;34m(self, vars, scaling, step_scale, is_cov, model, blocked, potential, dtype, Emax, target_accept, gamma, k, t0, adapt_step_size, step_rand, **pytensor_kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m get_value_vars_from_user_vars(\u001b[38;5;28mvars\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model)\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mvars\u001b[39m, blocked\u001b[38;5;241m=\u001b[39mblocked, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model, dtype\u001b[38;5;241m=\u001b[39mdtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpytensor_kwargs)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt_step_size \u001b[38;5;241m=\u001b[39m adapt_step_size\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEmax \u001b[38;5;241m=\u001b[39m Emax\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\step_methods\\arraystep.py:163\u001b[0m, in \u001b[0;36mGradientSharedStep.__init__\u001b[1;34m(self, vars, model, blocked, dtype, logp_dlogp_func, **pytensor_kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m model \u001b[38;5;241m=\u001b[39m modelcontext(model)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logp_dlogp_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     func \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlogp_dlogp_function(\u001b[38;5;28mvars\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpytensor_kwargs)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     func \u001b[38;5;241m=\u001b[39m logp_dlogp_func\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\model\\core.py:626\u001b[0m, in \u001b[0;36mModel.logp_dlogp_function\u001b[1;34m(self, grad_vars, tempered, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m ip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_point(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    621\u001b[0m extra_vars_and_values \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    622\u001b[0m     var: ip[var\u001b[38;5;241m.\u001b[39mname]\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_vars\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m input_vars \u001b[38;5;129;01mand\u001b[39;00m var \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m grad_vars\n\u001b[0;32m    625\u001b[0m }\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ValueGradFunction(costs, grad_vars, extra_vars_and_values, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\model\\core.py:321\u001b[0m, in \u001b[0;36mValueGradFunction.__init__\u001b[1;34m(self, costs, grad_vars, extra_vars_and_values, dtype, casting, compute_grads, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_vars_shared[var\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m shared\n\u001b[0;32m    319\u001b[0m     givens\u001b[38;5;241m.\u001b[39mappend((var, shared))\n\u001b[1;32m--> 321\u001b[0m cost \u001b[38;5;241m=\u001b[39m rewrite_pregrad(cost)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_grads:\n\u001b[0;32m    324\u001b[0m     grads \u001b[38;5;241m=\u001b[39m pytensor\u001b[38;5;241m.\u001b[39mgrad(cost, grad_vars, disconnected_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\pytensorf.py:1065\u001b[0m, in \u001b[0;36mrewrite_pregrad\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrewrite_pregrad\u001b[39m(graph):\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply simplifying or stabilizing rewrites to graph that are safe to use\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;124;03m    pre-grad.\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rewrite_graph(graph, include\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanonicalize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstabilize\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytensor\\graph\\rewriting\\utils.py:61\u001b[0m, in \u001b[0;36mrewrite_graph\u001b[1;34m(graph, include, custom_rewrite, clone, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     fgraph \u001b[38;5;241m=\u001b[39m FunctionGraph(outputs\u001b[38;5;241m=\u001b[39moutputs, clone\u001b[38;5;241m=\u001b[39mclone)\n\u001b[0;32m     60\u001b[0m query_rewrites \u001b[38;5;241m=\u001b[39m optdb\u001b[38;5;241m.\u001b[39mquery(RewriteDatabaseQuery(include\u001b[38;5;241m=\u001b[39minclude, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m---> 61\u001b[0m _ \u001b[38;5;241m=\u001b[39m query_rewrites\u001b[38;5;241m.\u001b[39mrewrite(fgraph)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_rewrite:\n\u001b[0;32m     64\u001b[0m     custom_rewrite\u001b[38;5;241m.\u001b[39mrewrite(fgraph)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:121\u001b[0m, in \u001b[0;36mGraphRewriter.rewrite\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03mThis is meant as a shortcut for the following::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_requirements(fgraph)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(fgraph, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:291\u001b[0m, in \u001b[0;36mSequentialGraphRewriter.apply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    289\u001b[0m nb_nodes_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fgraph\u001b[38;5;241m.\u001b[39mapply_nodes)\n\u001b[0;32m    290\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m--> 291\u001b[0m sub_prof \u001b[38;5;241m=\u001b[39m rewriter\u001b[38;5;241m.\u001b[39mapply(fgraph)\n\u001b[0;32m    292\u001b[0m l\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m t0))\n\u001b[0;32m    293\u001b[0m sub_profs\u001b[38;5;241m.\u001b[39mappend(sub_prof)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:2428\u001b[0m, in \u001b[0;36mEquilibriumGraphRewriter.apply\u001b[1;34m(self, fgraph, start_from)\u001b[0m\n\u001b[0;32m   2426\u001b[0m nb \u001b[38;5;241m=\u001b[39m change_tracker\u001b[38;5;241m.\u001b[39mnb_imported\n\u001b[0;32m   2427\u001b[0m t_rewrite \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m-> 2428\u001b[0m node_rewriter_change \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_node(\n\u001b[0;32m   2429\u001b[0m     fgraph, node, node_rewriter\n\u001b[0;32m   2430\u001b[0m )\n\u001b[0;32m   2431\u001b[0m time_rewriters[node_rewriter] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m t_rewrite\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node_rewriter_change:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:1920\u001b[0m, in \u001b[0;36mNodeProcessingGraphRewriter.process_node\u001b[1;34m(self, fgraph, node, node_rewriter)\u001b[0m\n\u001b[0;32m   1918\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m node_rewriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1920\u001b[0m     replacements \u001b[38;5;241m=\u001b[39m node_rewriter\u001b[38;5;241m.\u001b[39mtransform(fgraph, node)\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailure_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:1077\u001b[0m, in \u001b[0;36mFromFunctionNodeRewriter.transform\u001b[1;34m(self, fgraph, node)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, fgraph, node):\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracks:\n\u001b[0;32m   1076\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m-> 1077\u001b[0m             node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracked_types)\n\u001b[0;32m   1078\u001b[0m         ):\n\u001b[0;32m   1079\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(fgraph, node)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytensor\\graph\\utils.py:231\u001b[0m, in \u001b[0;36mMetaType.__new__.<locals>.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    227\u001b[0m     dct[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__hash__\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;21m__hash__\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dct:\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m props\n\u001b[0;32m    234\u001b[0m         ) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(other, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m props)\n\u001b[0;32m    236\u001b[0m     dct[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;21m__eq__\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load observed data (replace with actual Y_observed from your black-box model)\n",
    "Y_observed = pd.read_csv(\"Y_out.csv\", header=None).values.flatten()\n",
    "\n",
    "# Function to run the black-box model and get the output\n",
    "def black_box_likelihood(X_a):\n",
    "    \"\"\"\n",
    "    Calls the external black-box model to generate Y given input X_a.\n",
    "    Returns the generated output Y.\n",
    "    \"\"\"\n",
    "    # Convert PyMC tensor to NumPy array for saving (evaluate symbolic variables)\n",
    "    X_a_eval = np.array([X_a[i].eval() for i in range(3)]).reshape(1, -1)\n",
    "\n",
    "    # Save input to a temporary file\n",
    "    input_file = 'input_temp.txt'\n",
    "    np.savetxt(input_file, X_a_eval, delimiter=',')\n",
    "\n",
    "    # Run the black-box model\n",
    "    subprocess.run(['./local_model_windows.exe', input_file], capture_output=True, text=True)\n",
    "\n",
    "    # Load the generated output\n",
    "    output_file = 'Y_out.csv'\n",
    "    Y_generated = pd.read_csv(output_file, header=None).values.flatten()  # Ensure correct shape\n",
    "\n",
    "    return Y_generated\n",
    "\n",
    "# Bayesian Inference Model using PyMC\n",
    "with pm.Model() as model:\n",
    "    # Define priors for the three aleatory input variables (assumed uniform between 0 and 1)\n",
    "    X_a1 = pm.Uniform('X_a1', lower=0, upper=1)\n",
    "    X_a2 = pm.Uniform('X_a2', lower=0, upper=1)\n",
    "    X_a3 = pm.Uniform('X_a3', lower=0, upper=1)\n",
    "\n",
    "    # Stack the inputs into a single tensor\n",
    "    X_a = pm.math.stack([X_a1, X_a2, X_a3])\n",
    "\n",
    "    # Likelihood: Use the black-box model to get Y given X_a\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)  # Noise in the outputs\n",
    "    Y_obs = pm.Normal('Y_obs', mu=black_box_likelihood(X_a), sigma=sigma, observed=Y_observed)\n",
    "\n",
    "    # Perform MCMC sampling\n",
    "    trace = pm.sample(10, tune=2, chains=2, return_inferencedata=True)\n",
    "\n",
    "# Plot posterior distributions of the aleatory variables\n",
    "pm.plot_posterior(trace, var_names=['X_a1', 'X_a2', 'X_a3'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data written to input.txt\n",
      "Simulation executable has been called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define input parameters to the model\n",
    "# Define the input vector X_input with the required values\n",
    "X_input = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.1, 0.0, 42])\n",
    "# Alternatively, the model also supports a batch of N input vectors (as an example, \"N\" copies of X_input)\n",
    "N = 3\n",
    "X_input_batch = np.tile(X_input, (N, 1))  # Shape will be (N, 9)\n",
    "\n",
    "input_file_path = 'input.txt'\n",
    "np.savetxt(input_file_path, X_input_batch, delimiter=',')\n",
    "print(f'Input data written to {input_file_path}')\n",
    "\n",
    "# Step 3: Run the executable and capture its output\n",
    "exe_path = os.path.abspath(Path(os.getcwd()) / \"local_model_windows.exe\")  # Path to the executable in the current folder\n",
    "command = [exe_path, input_file_path]\n",
    "\n",
    "print('Simulation executable has been called.')\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "\n",
    "# Print the output from the executable\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save inputs to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data written to input.txt\n",
      "Simulation executable has been called.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the local blackbox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation executable has been called.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Output to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation output data loaded from Y_out.csv\n",
      "Output values for the first timestep for all 6 features of sample 3:\n",
      "[0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the output data\n",
    "# Load the output data from the CSV file into a pandas DataFrame\n",
    "output_file_path = 'Y_out.csv'\n",
    "df = pd.read_csv(output_file_path, header=None)\n",
    "print(f'Simulation output data loaded from {output_file_path}')\n",
    "\n",
    "# Step 2: Extract unique sample indices (number \"N\" if using batch input) and remove that column (Column 7 contains sample indices)\n",
    "sample_indices = df[6].unique()  # Extract unique sample indices\n",
    "num_samples = len(sample_indices)\n",
    "df = df.drop(columns=[6])  # Drop the sample index column\n",
    "\n",
    "# Step 3: Reshape the Output Data (6 features, 60 timesteps per simulation)\n",
    "# Convert DataFrame to a NumPy array and reshape/transpose to the desired 3D shape (num_time_steps x num features x num_samples)\n",
    "Y_out = df.to_numpy().reshape(num_samples, 60, 6).transpose(1, 2, 0)\n",
    "\n",
    "# Step 4: As an example, Print the First Time Step for All 6 Output Features of Sample 3\n",
    "print('Output values for the first timestep for all 6 features of sample 3:')\n",
    "print(Y_out[0, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No model on context stack, which is needed to instantiate distributions. Add variable inside a 'with model:' block, or use the '.dist' syntax for a standalone distribution.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\model\\core.py:137\u001b[0m, in \u001b[0;36mContextMeta.get_context\u001b[1;34m(cls, error_if_none, allow_block_model_access)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     candidate: T \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_contexts()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Calling code expects to get a TypeError if the entity\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# is unfound, and there's too much to fix.\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\distributions\\distribution.py:504\u001b[0m, in \u001b[0;36mDistribution.__new__\u001b[1;34m(cls, name, rng, dims, initval, observed, total_size, transform, default_transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m--> 504\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mget_context()\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\model\\core.py:142\u001b[0m, in \u001b[0;36mContextMeta.get_context\u001b[1;34m(cls, error_if_none, allow_block_model_access)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_none:\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on context stack\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: No <class 'pymc.model.core.Model'> on context stack",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m         Y_generated \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_out.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Y_generated\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Ensure correct shape\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m sigma \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mHalfNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Noise in the outputs\u001b[39;00m\n\u001b[0;32m     17\u001b[0m Y_obs \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_obs\u001b[39m\u001b[38;5;124m'\u001b[39m, mu\u001b[38;5;241m=\u001b[39mblack_box_likelihood(X_a), sigma\u001b[38;5;241m=\u001b[39msigma, observed\u001b[38;5;241m=\u001b[39mY_observed\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Perform MCMC sampling\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pymc\\distributions\\distribution.py:506\u001b[0m, in \u001b[0;36mDistribution.__new__\u001b[1;34m(cls, name, rng, dims, initval, observed, total_size, transform, default_transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mget_context()\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model on context stack, which is needed to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstantiate distributions. Add variable inside \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith model:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m block, or use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.dist\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m syntax \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor a standalone distribution.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m     )\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtestval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    514\u001b[0m     initval \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtestval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: No model on context stack, which is needed to instantiate distributions. Add variable inside a 'with model:' block, or use the '.dist' syntax for a standalone distribution."
     ]
    }
   ],
   "source": [
    "# Bayesian inference\n",
    "with pm.Model() as model:\n",
    "    # Priors for aleatory input variables (X_a1, X_a2, X_a3)\n",
    "    X_a1 = pm.Uniform('X_a1', lower=0, upper=1)\n",
    "    X_a2 = pm.Uniform('X_a2', lower=0, upper=1)\n",
    "    X_a3 = pm.Uniform('X_a3', lower=0, upper=1)\n",
    "\n",
    "\n",
    "def black_box_likelihood(X_a):\n",
    "    # Load the generated output\n",
    "        Y_generated = pd.read_csv('Y_out.csv', header=None).values\n",
    "\n",
    "        return Y_generated.flatten()  # Ensure correct shape\n",
    "\n",
    "\n",
    "sigma = pm.HalfNormal('sigma', sigma=1)  # Noise in the outputs\n",
    "Y_obs = pm.Normal('Y_obs', mu=black_box_likelihood(X_a), sigma=sigma, observed=Y_observed.flatten())\n",
    "\n",
    "# Perform MCMC sampling\n",
    "trace = pm.sample(2000, tune=1000, chains=2, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
